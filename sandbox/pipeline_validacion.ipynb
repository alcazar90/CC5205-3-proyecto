{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c1ae4e",
   "metadata": {},
   "source": [
    "# Pipeline de Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361229ad",
   "metadata": {},
   "source": [
    "Cargamos las tablas de validación desde el github. Estas contienen track_features y playlists de las 50 playlists con más canciones del dataset de 2000 playlists. Ya se encuentran limpiadas (ambas tablas sólo contienen info de canciones de menos de 15 minutos y sin valores nulos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "abf88b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uri</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>track_href</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:3RCT90rX7F5rSwMwUU4Pz6</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.850</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.419</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.00216</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.470</td>\n",
       "      <td>142.841</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>3RCT90rX7F5rSwMwUU4Pz6</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/3RCT90rX7F5r...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/3RCT...</td>\n",
       "      <td>219560</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:2t5GyUfFoZg3E8ak3i7dVP</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.353</td>\n",
       "      <td>4</td>\n",
       "      <td>-15.588</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.77800</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.189</td>\n",
       "      <td>134.588</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2t5GyUfFoZg3E8ak3i7dVP</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2t5GyUfFoZg3...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2t5G...</td>\n",
       "      <td>621107</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   uri  danceability  energy  \\\n",
       "0           0  spotify:track:3RCT90rX7F5rSwMwUU4Pz6         0.616   0.850   \n",
       "1           1  spotify:track:2t5GyUfFoZg3E8ak3i7dVP         0.301   0.353   \n",
       "\n",
       "   key  loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0    5    -5.419     0       0.0580       0.00216            0.0667     0.181   \n",
       "1    4   -15.588     0       0.0467       0.77800            0.4890     0.406   \n",
       "\n",
       "   valence    tempo            type                      id  \\\n",
       "0    0.470  142.841  audio_features  3RCT90rX7F5rSwMwUU4Pz6   \n",
       "1    0.189  134.588  audio_features  2t5GyUfFoZg3E8ak3i7dVP   \n",
       "\n",
       "                                          track_href  \\\n",
       "0  https://api.spotify.com/v1/tracks/3RCT90rX7F5r...   \n",
       "1  https://api.spotify.com/v1/tracks/2t5GyUfFoZg3...   \n",
       "\n",
       "                                        analysis_url  duration_ms  \\\n",
       "0  https://api.spotify.com/v1/audio-analysis/3RCT...       219560   \n",
       "1  https://api.spotify.com/v1/audio-analysis/2t5G...       621107   \n",
       "\n",
       "   time_signature  \n",
       "0               4  \n",
       "1               3  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "playlists_val = pd.read_csv('https://github.com/alcazar90/CC5205-3-proyecto/raw/main/data/validacion/50_playlists_validation.csv')\n",
    "tracks_val = pd.read_csv('https://github.com/alcazar90/CC5205-3-proyecto/raw/main/data/validacion/50_tracks_validation.csv')\n",
    "artist_info = pd.read_csv('https://github.com/alcazar90/CC5205-3-proyecto/raw/main/data/artist/2000_artist_sample.csv.gz')\n",
    "cols=tracks_val.columns\n",
    "tracks_val.columns=[col[15:] if col[:15]==\"audio_features.\" else col for col in cols]\n",
    "tracks_val.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef096021",
   "metadata": {},
   "source": [
    "`var_names` para obtener los features que nos sirven y `tracks_info` para obtener información de una canción dada una `uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "4144aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names=[\"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\", \"time_signature\"]\n",
    "tracks_info = playlists_val.drop_duplicates(subset=[\"track_uri\"]).set_index(\"track_uri\")[[\"track_name\", \"artist_name\"]].loc[tracks_val[\"uri\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877426c9",
   "metadata": {},
   "source": [
    "Definir clases para cada recomendador y así poder evaluarlos. Colocarlas en el espacio y formato del siguiente \n",
    "_template_:\n",
    "\n",
    "```python\n",
    "#Colocar acá las clases de sus clasificadores.\n",
    "#Pueden o no tener init o train, pero deben tener una función recommend_list\n",
    "class recommender_x:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    #Puede no tener train, dependiendo de cómo funcione. Pero debe utilizar las canciones dentro del dataset de validación.\n",
    "    def train(self, tracks_df, playlists_df):\n",
    "        pass\n",
    "    #Esta función DEBE tomar como input un dataframe de canciones.\n",
    "    #Debe tambien tomar el argumento \"number\" para setear el número de recomendaciones\n",
    "    def recommend_list(self, canciones_df, number=100, **kwargs):\n",
    "        #DEBE retornar una lista de uris de las canciones output \n",
    "        return None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd5a7a",
   "metadata": {},
   "source": [
    "Calculamos la métrica en los datos de validación. Para una lista dada, se eligen aleatoreamente 20 canciones que pertenezcan a la lista y se obtienen N-20 recomendaciones, donde N es la cantidad de canciones de la lista (las listas del dataset de validación tienen entre 210-375 canciones). Luego, evalúa qué porcentaje de las N-20 canciones output pertenecen a la lista original. Repite este proceso. Se grafica el histograma de desempeño del recomendador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "40e1cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1991)\n",
    "\n",
    "def validar_lista(pid, recomendador):\n",
    "    input_uris= list(set(playlists_val[playlists_val[\"pid\"]==pid][\"track_uri\"]))\n",
    "    input_df=tracks_val.set_index(\"uri\").loc[np.random.choice(input_uris, 20)]\n",
    "    output_uris= recomendador.recommend_list(input_df, number=len(input_uris)-20)\n",
    "    output_pid= playlists_val.set_index(\"track_uri\").loc[output_uris][\"pid\"]\n",
    "    return sum(output_pid==pid)*100.0/(len(input_uris)-20)\n",
    "\n",
    "def validar_recomendador(recomendador):\n",
    "    porcentajes=[]\n",
    "    for i, pid in enumerate(list(set(playlists_val[\"pid\"]))):\n",
    "        porcentajes.append(validar_lista(pid, recomendador))\n",
    "        print(i+1,\"de\", len(set(playlists_val[\"pid\"]))) if (i+1)%5==0 else None\n",
    "    plt.hist(porcentajes)\n",
    "    return np.mean(porcentajes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bd0b3",
   "metadata": {},
   "source": [
    "## Sistema de Recomendación 1: Matriz de próximidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "7e3969b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class recommender_1:\n",
    "  def __init__(self):\n",
    "    self.proximity_matrix=None\n",
    "    self.obs_labels=None\n",
    "    self.N_nearest=None\n",
    "    self.artist=None\n",
    "    self.pid_id=None\n",
    "    self.avg_features_by_pid=None\n",
    "\n",
    "  def fit(self, X, y, artist):\n",
    "    \"\"\"Almacena la matriz de proximidad y guarda los PID en self.obs_labels\"\"\"\n",
    "    self.avg_features_by_pid = X\n",
    "    self.obs_labels = y\n",
    "    self.proximity_matrix = distance_matrix(X, X)\n",
    "    self.artist = artist\n",
    "    \n",
    "  def refit(self):\n",
    "    \"\"\"Actualiza la matriz de distancia en base a self.avg_features_by_pid\"\"\"\n",
    "    self.proximity_matrix = distance_matrix(self.avg_features_by_pid, self.avg_features_by_pid)\n",
    "    \n",
    "  def recommend_list(self, canciones_df, number=2, N=50, **kwargs):\n",
    "    \"\"\"\n",
    "       Recibe un set de canciones sin PID con sus track_features (canciones_df).\n",
    "       Se recomputa self.proximity_matrix agregando el nuevo set de canciones\n",
    "       como PID \"pivote\". Se deja reservado el PID 0 para este set de canciones.\n",
    "       \n",
    "           - canciones_df: dataframe con una lista de canciones\n",
    "           - number: número de canciones requeridas para recomendar\n",
    "           - N: número de playlist cercanas para ir a buscar candidatos de canciones\n",
    "    \"\"\"\n",
    "    # Preproceso para computar el vector de características promedio\n",
    "    canciones_df = \\\n",
    "            canciones_df.reset_index() \\\n",
    "            [['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "              'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']]\n",
    "        \n",
    "    track_set = pd.concat([pd.DataFrame({'PID': np.zeros(canciones_df.shape[0], 'int32')}),\n",
    "                           canciones_df], axis=1)\n",
    "        \n",
    "    # Se computa el vector de características promedio del set de canciones recibido\n",
    "    track_set = track_set.groupby('PID').mean().reset_index()\n",
    "   \n",
    "    # Concatenar al principio del atributo self.avg_features_by_pid y self.obs_labels\n",
    "    self.avg_features_by_pid = np.r_[track_set.iloc[:, 1:], self.avg_features_by_pid]\n",
    "    self.obs_labels = np.r_[0, self.obs_labels]\n",
    "    \n",
    "    # Actualizar matriz de distancia\n",
    "    self.refit()\n",
    "    \n",
    "    # Actualizar listas mas cercanas (siempre es el PID en la posición 0)\n",
    "    nearest_index = np.argsort(self.proximity_matrix[0, :])[:N+1][1:]\n",
    "    self.N_nearest = self.obs_labels[nearest_index]\n",
    "    \n",
    "    # Se cambia el atributo pid_id la cual es la lista objetivo para buscar las recomendaciones\n",
    "    self.pid_id = 0\n",
    "    \n",
    "    # Entregar recomendaciones\n",
    "    return self.get_recommendations(num_tracks=number)\n",
    "    \n",
    "  def get_recommendations(self, num_tracks=20):\n",
    "    \"\"\"Dado un track de canciones arbitarias, se utiliza por el método\n",
    "       recommend_given_track_set\n",
    "    \"\"\" \n",
    "    recommended_songs_list = self.artist[self.artist.pid.isin(self.N_nearest)].copy()\n",
    "    recommended_songs_list = recommended_songs_list.drop_duplicates(subset=['artist_uri'])\n",
    "    \n",
    "    # Seleccionar solo los features de las canciones\n",
    "    features_columns = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "     'speechiness', 'acousticness', 'instrumentalness', \n",
    "     'liveness', 'valence', 'tempo']\n",
    "    \n",
    "    # Obtenemos las canciones candidatas     \n",
    "    recommended_songs_list['similarity'] = np.dot(recommended_songs_list[features_columns].to_numpy(), \n",
    "                                                  self.avg_features_by_pid[0, :].reshape(11, 1))\n",
    "    recommended_songs_list = recommended_songs_list.sort_values(by=['similarity'], ascending=True)\n",
    "    \n",
    "    # Se eliminan los duplicados.\n",
    "    recommended_songs_list = recommended_songs_list.drop_duplicates(subset=['artist_uri'])\n",
    "    \n",
    "    # Se retorna el número de canciones, 2: track_uri\n",
    "    return recommended_songs_list.iloc[:num_tracks, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f81c37",
   "metadata": {},
   "source": [
    "El modelo requiere memorizar el vector de características promedio de cada lista en el set de entrenamiento.\n",
    "Por lo tanto, se debe cruzar la tabla con la información de las listas con los _track features_ de cada una \n",
    "de las canciones que contienen las _playlists_, para luego agregarlas en un vector promedio de _track features_ por lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "33bfc622",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_features_by_pid = \\\n",
    "        playlists_val \\\n",
    "            .merge(tracks_val, left_on='track_uri', right_on='uri', how='inner') \\\n",
    "            [['pid','danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "              'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']] \\\n",
    "            .groupby('pid') \\\n",
    "            .mean() \\\n",
    "            .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "3e35af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_by_pid_plus_artist = \\\n",
    "    playlists_val \\\n",
    "    .merge(tracks_val, left_on='track_uri', right_on='uri', how='inner') \\\n",
    "    [['pid','artist_uri', 'track_uri', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']] \\\n",
    "    .drop_duplicates(subset=['artist_uri']) \\\n",
    "    .merge(artist_info[['artists.uri', 'artists.popularity']], left_on='artist_uri', right_on='artists.uri', how='left') \\\n",
    "    .drop(['artists.uri'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "51363283",
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendador_1 =recommender_1()\n",
    "recomendador_1.fit(avg_features_by_pid.iloc[:, 1:].to_numpy(), \n",
    "                   avg_features_by_pid.iloc[:, 0].to_numpy(),\n",
    "                   features_by_pid_plus_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c43ea3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 de 50\n",
      "10 de 50\n",
      "15 de 50\n",
      "20 de 50\n",
      "25 de 50\n",
      "30 de 50\n",
      "35 de 50\n",
      "40 de 50\n",
      "45 de 50\n",
      "50 de 50\n",
      "Eficiencia recomendador 1: 5.390204330013585 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1991)\n",
    "eficiencia_1=validar_recomendador(recomendador_1)\n",
    "print(\"Eficiencia recomendador 1:\", eficiencia_1,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a696c56",
   "metadata": {},
   "source": [
    "## Sistema de Recomendación 2: Multi-label logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "d8aa5f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class recommender_2:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, tracks_df, playlists_df):\n",
    "        self.tracks_df, self.playlists_df = tracks_df, playlists_df\n",
    "        playlist_ids=list(set(playlists_df[\"pid\"]))\n",
    "        self.X_ori=np.asarray(tracks_df[var_names])\n",
    "        self.X=(self.X_ori-np.tile(np.mean(self.X_ori, axis=0), (self.X_ori.shape[0], 1)))/np.tile(np.std(self.X_ori, axis=0), (self.X_ori.shape[0], 1))\n",
    "        self.X_t=PolynomialFeatures(1).fit_transform(self.X)\n",
    "        self.W=np.zeros(0)\n",
    "        total=len(playlist_ids)\n",
    "        self.lists=np.zeros(shape=(len(self.X), total))-1\n",
    "        for playlist_i in range(total):\n",
    "            print(playlist_i) if (playlist_i % (total/5))==0 else None\n",
    "            this_playlist=playlists_df[playlists_df[\"pid\"]==playlist_ids[playlist_i]]\n",
    "            y=1*tracks_df[\"uri\"].isin(this_playlist[\"track_uri\"])\n",
    "            if(sum(y))>0:\n",
    "                self.lists[y==1, playlist_i]=playlist_i\n",
    "                clf=LogisticRegression(fit_intercept=False)\n",
    "                clf.fit(self.X_t, y)\n",
    "                self.W=np.append(self.W, clf.coef_)\n",
    "        self.lists=np.asarray(self.lists)\n",
    "        self.W=self.W.reshape(-1, clf.coef_.size)\n",
    "        ret=np.exp(self.X_t @ self.W.T-10)\n",
    "        self.probas=ret/np.tile(np.apply_along_axis(sum, 1, ret), (self.W.T.shape[1],1)).T\n",
    "        \n",
    "    def recommend_list(self, canciones_df, suavizado=1000, number=100, exclude_same=True):\n",
    "        canciones=np.asarray(canciones_df[var_names])\n",
    "        canciones=np.asarray(canciones).reshape(-1, 13)\n",
    "        canciones=(canciones-np.tile(np.mean(self.X_ori, axis=0), (canciones.shape[0], 1)))/np.tile(np.std(self.X_ori, axis=0), (canciones.shape[0], 1))\n",
    "        canciones_t=PolynomialFeatures(1).fit_transform(canciones)\n",
    "        matmult=np.exp(canciones_t @ self.W.T-10)\n",
    "        probas_canciones=matmult/np.tile(np.apply_along_axis(sum, 1, matmult), (self.W.T.shape[1],1)).T\n",
    "        puntajes=np.zeros(len(self.X))\n",
    "        not_in_input=np.ones(len(self.X))\n",
    "        for this_proba in probas_canciones:\n",
    "            distancia_proba=np.asarray([np.linalg.norm(this_proba-proba) for proba in self.probas])\n",
    "            not_in_input=not_in_input*(distancia_proba>1e-15)*1 if exclude_same else not_in_input\n",
    "            order=np.argsort(np.argsort(distancia_proba))\n",
    "            puntajes+=np.exp(-order*len(canciones)/suavizado)\n",
    "        puntajes=puntajes*not_in_input if exclude_same else puntajes\n",
    "        final_order=np.argsort(-puntajes)\n",
    "        y_recom=np.zeros(len(self.X))\n",
    "        y_recom[final_order[:number]]=1\n",
    "        return self.tracks_df.iloc[final_order][:number][\"uri\"]\n",
    "\n",
    "recomendador_2=recommender_2()\n",
    "recomendador_2.train(tracks_val, playlists_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "72e66713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 de 50\n",
      "10 de 50\n",
      "15 de 50\n",
      "20 de 50\n",
      "25 de 50\n",
      "30 de 50\n",
      "35 de 50\n",
      "40 de 50\n",
      "45 de 50\n",
      "50 de 50\n",
      "Eficiencia recomendador 2: 15.618249962782562 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1991)\n",
    "eficiencia_2=validar_recomendador(recomendador_2)\n",
    "print(\"Eficiencia recomendador 2:\", eficiencia_2,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de20fb7",
   "metadata": {},
   "source": [
    "## Sistema de Recomendación 3: Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d76cc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a781f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la clase autoencoder.\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(11, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 11))\n",
    "        \n",
    "    def predict(self, data):\n",
    "        return self.encoder(data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.encoder(x)\n",
    "        decoder = self.decoder(encoder)\n",
    "        return decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27737b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la clase GenerateDataset para leer los datos.\n",
    "class GenerateDataset(Dataset):\n",
    "    def __init__(self, numpy_array):\n",
    "        self.numpy_array = numpy_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numpy_array)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.numpy_array[idx]\n",
    "        x = np.isnan(data)\n",
    "        data[x] = 0\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca86716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommender_3:\n",
    "    def __init__(self, path=\"../data/models/modelo_50e_256b_decay.pth\"):\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = autoencoder().to(self.device)\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        self.data = None\n",
    "        self.processed_data = []\n",
    "        self.processed_data_df = None\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def load_data(self, tracks_val):\n",
    "        self.scaler.fit(tracks_val.iloc[:, 2:-6])\n",
    "        tracks_val_np = self.scaler.transform(tracks_val.iloc[:, 2:-6])\n",
    "        self.data = DataLoader(GenerateDataset(tracks_val_np.astype('f')),\n",
    "                    batch_size=1, shuffle=False)\n",
    "        \n",
    "        for data in self.data:\n",
    "            data = data.to(self.device)\n",
    "            self.processed_data.append(self.model.predict(data).detach().cpu().numpy()[0])\n",
    "        \n",
    "        self.processed_data_df = pd.DataFrame(self.processed_data, columns=['comp_1','comp_2'])\n",
    "        self.processed_data_df = self.processed_data_df.assign(uri=tracks_val['uri'])\n",
    "    \n",
    "    \n",
    "    #Esta función DEBE tomar como input un dataframe de canciones.\n",
    "    #Debe tambien tomar el argumento \"number\" para setear el número de recomendaciones\n",
    "    def recommend_list(self, canciones_df, number=100, **kwargs):\n",
    "        canciones_np = self.scaler.transform(canciones_df[var_names[:-2]])\n",
    "        canciones_dl = DataLoader(GenerateDataset(canciones_np.astype('f')),\n",
    "                    batch_size=1, shuffle=False)\n",
    "        \n",
    "        data_inference = []\n",
    "        for data in canciones_dl:\n",
    "            data = data.to(self.device)\n",
    "            data_inference.append(self.model.predict(data).detach().cpu().numpy()[0])\n",
    "        \n",
    "        data_inference_df = pd.DataFrame(data_inference, columns=['comp_1','comp_2'])\n",
    "        canciones_df = canciones_df.reset_index()\n",
    "        data_inference_df = data_inference_df.assign(uri=canciones_df[\"uri\"])\n",
    "        \n",
    "        # inferencia\n",
    "        recommendations = []\n",
    "        amount = int(number/canciones_df.shape[0]) + 5\n",
    "        for i in range(canciones_df.shape[0]):\n",
    "            # Se toma la primera playlist/cancion y se pasa a tensor.\n",
    "            playlist_input = torch.tensor(data_inference_df.iloc[i:i+1,:2].to_numpy())\n",
    "            \n",
    "            # processed_data_df son las canciones procesadas por .encoder (espacio latente).\n",
    "            dataset_latente = torch.tensor(self.processed_data_df.iloc[:,:2].to_numpy())\n",
    "\n",
    "            # Se buscan las canciones mas cercanas a la playlist/cancion de input.\n",
    "            result_cdist = torch.cdist(playlist_input, dataset_latente, p=2)\n",
    "\n",
    "            # Se ordenan los valores.\n",
    "            result_cdist_sort = [x.item() for x in np.argsort(result_cdist)[0]][:amount]\n",
    "            recommendations.extend(result_cdist_sort)\n",
    "            \n",
    "        return self.processed_data_df.iloc[recommendations[1:number+1], 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0811fd42",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recomendador_3 \u001b[38;5;241m=\u001b[39m \u001b[43mrecommender_3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mrecommender_3.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m autoencoder()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/eda/lib/python3.8/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/eda/lib/python3.8/site-packages/torch/serialization.py:1046\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1044\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1045\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1046\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/eda/lib/python3.8/site-packages/torch/serialization.py:1016\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1015\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1016\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/eda/lib/python3.8/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    997\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39m_UntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_untyped()\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> 1001\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1002\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/eda/lib/python3.8/site-packages/torch/serialization.py:176\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 176\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/eda/lib/python3.8/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             storage_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda, \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.5/envs/eda/lib/python3.8/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "recomendador_3 = recommender_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f975e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendador_3.load_data(tracks_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a1240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1991)\n",
    "eficiencia_3 = validar_recomendador(recomendador_3)\n",
    "print(\"Eficiencia recomendador 3:\", eficiencia_3,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
